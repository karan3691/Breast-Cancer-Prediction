{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           0         M        17.99         10.38          122.80     1001.0   \n",
       "1           1         M        20.57         17.77          132.90     1326.0   \n",
       "2           2         M        19.69         21.25          130.00     1203.0   \n",
       "3           3         M        11.42         20.38           77.58      386.1   \n",
       "4           4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38           122.8     1001.0   \n",
       "1         M        20.57         17.77           132.9     1326.0   \n",
       "2         M        19.69         21.25           130.0     1203.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33            184.6   \n",
       "1         0.1812  ...         24.99          23.41            158.8   \n",
       "2         0.2069  ...         23.57          25.53            152.5   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    object \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  False\n",
       "radius_mean                False\n",
       "texture_mean               False\n",
       "perimeter_mean             False\n",
       "area_mean                  False\n",
       "smoothness_mean            False\n",
       "compactness_mean           False\n",
       "concavity_mean             False\n",
       "concave points_mean        False\n",
       "symmetry_mean              False\n",
       "fractal_dimension_mean     False\n",
       "radius_se                  False\n",
       "texture_se                 False\n",
       "perimeter_se               False\n",
       "area_se                    False\n",
       "smoothness_se              False\n",
       "compactness_se             False\n",
       "concavity_se               False\n",
       "concave points_se          False\n",
       "symmetry_se                False\n",
       "fractal_dimension_se       False\n",
       "radius_worst               False\n",
       "texture_worst              False\n",
       "perimeter_worst            False\n",
       "area_worst                 False\n",
       "smoothness_worst           False\n",
       "compactness_worst          False\n",
       "concavity_worst            False\n",
       "concave points_worst       False\n",
       "symmetry_worst             False\n",
       "fractal_dimension_worst    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           # of observations\n",
       "diagnosis                   \n",
       "B                        357\n",
       "M                        212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_gr = df.groupby('diagnosis', axis=0)\n",
    "pd.DataFrame(diag_gr.size(), columns=['# of observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diagnosis\"] = (df[\"diagnosis\"] == \"M\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['#8dd3c7', '#ffffb3'] \n",
    "value_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(value_counts.index, value_counts, color=colors)\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Plot of diagnosis')\n",
    "plt.legend(['Malignant','Benign'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = df.values\n",
    "X = array[:,1:31]\n",
    "y = array[:,0]\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y\n",
    "\n",
    "# Call the transform method of LabelEncorder on two dummy variables\n",
    "# le.transform (['M', 'B'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (426,), (143, 30), (143,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##Split data set in train 70% and test 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign predictors to a variable of ndarray (matrix) type\n",
    "array = df.values\n",
    "X = array[:,1:31] # features\n",
    "y = array[:,0]\n",
    "\n",
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Normalize the  data (center around 0 and scale to remove the variance).\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        98\n",
      "           1       0.93      0.89      0.91        45\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        98\n",
      "           1       0.95      0.89      0.92        45\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.95      0.93      0.94       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        98\n",
      "           1       0.97      0.84      0.90        45\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.95      0.92      0.93       143\n",
      "weighted avg       0.95      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lg_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        98\n",
      "           1       1.00      0.78      0.88        45\n",
      "\n",
      "    accuracy                           0.93       143\n",
      "   macro avg       0.95      0.89      0.91       143\n",
      "weighted avg       0.94      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same PCA model\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit a Logistic Regression model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        98\n",
      "           1       0.97      0.80      0.88        45\n",
      "\n",
      "    accuracy                           0.93       143\n",
      "   macro avg       0.94      0.89      0.91       143\n",
      "weighted avg       0.93      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
